{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739745ec",
   "metadata": {
    "collapsed": false,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|default_exp pyrnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f3830",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PyrNet high level data\n",
    "In the following high-level functions to read and examine PyrNet data are collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe58af7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "from collections.abc import Iterable\n",
    "from xml.dom import minidom\n",
    "from urllib.request import urlopen\n",
    "import parse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.interpolate import interp1d\n",
    "from toolz import valfilter, cons, merge_with\n",
    "import pkg_resources as pkg_res\n",
    "\n",
    "# python -m pip install git+https://github.com/hdeneke/trosat-base.git#egg=trosat-base\n",
    "from trosat import sunpos as sp\n",
    "\n",
    "from pyrnet import utils as pyrutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5660bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extra imports for demonstration\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e4bd1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data from Thredds-Server\n",
    "Acquire processed data from server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394122fa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "# campaign file name map for hdcp2 data\n",
    "campaign_pfx = {\n",
    "    'eifel': 'hope',\n",
    "    'hope_juelich': 'hope',\n",
    "    'hope_melpitz': 'hopm',\n",
    "    'lindenberg': 'ioprao',\n",
    "    'melcol': 'mcol',\n",
    "}\n",
    "\n",
    "# TROPOS thredds urls templates\n",
    "DATA_URL = \"https://tds.tropos.de/thredds/dodsC/scccJher/{dt:%Y}_{campaign}/\"\n",
    "FNAME_FMT_HDCP2 = '{campaign_pfx}_trop_pyrnet00_l1_rsds_v00_{dt:%Y%m%d}000000.nc'\n",
    "\n",
    "# configuration constants\n",
    "SOLCONST = 1359.0 # Solar constant in Wm-2\n",
    "MAX_MISSING = 1000 # Maximum allowed number of missing records\n",
    "MIN_GOOD = 85400 # Minimum allowed number of good records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf3bb7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Thredds lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69f6cd8",
   "metadata": {
    "collapsed": false,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "#|dropcode\n",
    "def get_elements(url, tag_name='dataset', attribute_name='urlPath'):\n",
    "  \"\"\"Get elements from an XML file\"\"\"\n",
    "  # usock = urllib2.urlopen(url)\n",
    "  usock = urlopen(url)\n",
    "  xmldoc = minidom.parse(usock)\n",
    "  usock.close()\n",
    "  tags = xmldoc.getElementsByTagName(tag_name)\n",
    "  attributes=[]\n",
    "  for tag in tags:\n",
    "    attribute = tag.getAttribute(attribute_name)\n",
    "    attributes.append(attribute)\n",
    "  return attributes\n",
    "\n",
    "def parse_thredds_catalog(url, fname_format):\n",
    "    \"\"\"Parse Thredds server catalog and return pd.Dataframe of file name format variables.\"\"\"\n",
    "    fname_format = fname_format.replace(\"%Y-%m-%d\",\"ti\")\n",
    "    tfiles = get_elements(url)\n",
    "    results = False\n",
    "    for fn in tfiles:\n",
    "        fn = os.path.basename(fn)\n",
    "        res = parse.parse(fname_format, fn)\n",
    "        if res is None:\n",
    "            continue\n",
    "        if not results:\n",
    "            results = {k:[v] for k,v in res.named.items()}\n",
    "        else:\n",
    "            results = merge_with(lambda x: list(cons(x[1],x[0])), results, res.named)\n",
    "    return pd.DataFrame.from_dict(results)\n",
    "\n",
    "def lookup_fnames(date, *, station, lvl, campaign, collection):\n",
    "    \"\"\"Parse Thredds server files and return list of filenames matching the date, station, campaign and collection configuration.\"\"\"\n",
    "    date = pyrutils.to_datetime64(date)\n",
    "\n",
    "    if not isinstance(station, Iterable):\n",
    "        station=[station]\n",
    "\n",
    "    fn = pkg_res.resource_filename(\"pyrnet\", \"share/pyrnet_config.json\")\n",
    "    pyrcfg = pyrutils.read_json(fn)\n",
    "\n",
    "    # construct catalog url\n",
    "    catalog_url = DATA_URL.format(dt=pd.to_datetime(date),campaign=campaign)\n",
    "    catalog_url = catalog_url.replace(\"dodsC\",\"catalog\")\n",
    "    catalog_url += f\"{lvl}/catalog.xml\"\n",
    "    catalog = parse_thredds_catalog(catalog_url, pyrcfg[f\"output_{lvl}\"])\n",
    "\n",
    "    # file name blueprint\n",
    "    fname = DATA_URL + f\"{lvl}/\"+ pyrcfg[f\"output_{lvl}\"]\n",
    "\n",
    "    fnames = []\n",
    "    for st in station:\n",
    "        if collection is None:\n",
    "            c = catalog.query(f'station=={st}')\n",
    "            col = np.nanmax(c['collection'])\n",
    "        else:\n",
    "            col = collection\n",
    "\n",
    "        if lvl=='l1a':\n",
    "            c = catalog.query(f'station=={st} & collection=={col}').reset_index()\n",
    "            startdts = c[\"startdt\"]\n",
    "            enddts = c[\"enddt\"]\n",
    "            # get file index with maintenance interaval including date\n",
    "            idate_start = np.sum(date>=startdts)-1\n",
    "            idate_end = np.sum(date>enddts)\n",
    "            if (idate_start==-1) or (idate_end==enddts.size):\n",
    "                raise ValueError(f\"File of level {lvl} at date {date} does not exist.\")\n",
    "\n",
    "            fnames.append(\n",
    "                pyrcfg[f\"output_{lvl}\"].format(\n",
    "                    startdt=pd.to_datetime(startdts[idate_end]),\n",
    "                    enddt=pd.to_datetime(enddts[idate_end]),\n",
    "                    campaign=campaign,\n",
    "                    station=st,\n",
    "                    collection=col,\n",
    "                    sfx=\"nc\"\n",
    "                )\n",
    "            )\n",
    "            if idate_end!=idate_start: # date is on a maintenance day -> combine two datasets\n",
    "                fnames.append(\n",
    "                    pyrcfg[f\"output_{lvl}\"].format(\n",
    "                        startdt=pd.to_datetime(startdts[idate_start]),\n",
    "                        enddt=pd.to_datetime(enddts[idate_start]),\n",
    "                        campaign=campaign,\n",
    "                        station=st,\n",
    "                        collection=col,\n",
    "                        sfx=\"nc\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            fnames.append(\n",
    "                pyrcfg[f\"output_{lvl}\"].format(\n",
    "                    dt=pd.to_datetime(date),\n",
    "                    campaign=campaign,\n",
    "                    station=st,\n",
    "                    collection=col,\n",
    "                    sfx=\"nc\"\n",
    "                )\n",
    "            )\n",
    "    return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945de55b",
   "metadata": {
    "collapsed": false,
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-08-01_2019-08-06_metpvnet_st015_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-07_metpvnet_st086_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-07_metpvnet_st047_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-07_metpvnet_st046_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-07_metpvnet_st024_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-07_metpvnet_st009_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-07_metpvnet_st007_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-07_metpvnet_st005_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-31_2019-08-06_metpvnet_st025_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st087_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st060_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st055_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st053_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st044_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st043_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st038_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st035_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st033_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st032_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st026_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-07_metpvnet_st010_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-06_metpvnet_st037_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-06_metpvnet_st018_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-30_2019-08-06_metpvnet_st012_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-08-01_metpvnet_st015_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-31_metpvnet_st086_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-31_metpvnet_st054_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-31_metpvnet_st046_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-31_metpvnet_st025_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-31_metpvnet_st024_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-31_metpvnet_st007_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-31_metpvnet_st005_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-30_metpvnet_st053_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-30_metpvnet_st037_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-24_2019-07-30_metpvnet_st018_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-31_metpvnet_st047_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st087_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st060_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st055_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st044_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st043_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st038_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st035_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st033_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st032_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st026_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st012_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-23_2019-07-30_metpvnet_st010_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-17_2019-07-24_metpvnet_st015_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st086_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st054_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st053_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st046_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st037_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st025_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st024_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st018_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st009_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st007_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-16_2019-07-24_metpvnet_st005_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st087_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st060_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st055_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st044_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st043_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st038_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st035_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st033_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st032_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st026_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st012_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-23_metpvnet_st010_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-15_2019-07-15_metpvnet_st014_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-17_metpvnet_st015_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st086_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st054_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st046_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st037_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st025_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st024_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st018_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st009_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st007_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-16_metpvnet_st005_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-09_2019-07-15_metpvnet_st012_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-16_metpvnet_st053_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st087_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st060_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st055_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st044_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st043_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st038_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st035_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st033_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st032_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st026_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st014_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-08_2019-07-15_metpvnet_st010_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-05_2019-07-08_metpvnet_st053_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-05_2019-07-08_metpvnet_st043_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-05_2019-07-08_metpvnet_st035_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-05_2019-07-08_metpvnet_st026_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-05_2019-07-08_metpvnet_st014_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-05_2019-07-08_metpvnet_st010_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st054_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st046_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st037_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st025_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st024_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st018_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st012_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-09_metpvnet_st005_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-08_metpvnet_st087_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-08_metpvnet_st060_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-08_metpvnet_st055_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-08_metpvnet_st044_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-04_2019-07-08_metpvnet_st038_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-02_2019-07-09_metpvnet_st086_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-02_2019-07-09_metpvnet_st009_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-07-02_2019-07-09_metpvnet_st007_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-27_2019-07-09_metpvnet_st015_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-27_2019-07-04_metpvnet_st054_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-05_metpvnet_st053_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-05_metpvnet_st026_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-05_metpvnet_st014_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-05_metpvnet_st010_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-04_metpvnet_st087_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-04_metpvnet_st055_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-04_metpvnet_st044_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-26_2019-07-04_metpvnet_st012_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-08_metpvnet_st047_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-08_metpvnet_st032_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-07_metpvnet_st033_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-05_metpvnet_st043_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-05_metpvnet_st035_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-04_metpvnet_st060_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-04_metpvnet_st046_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-04_metpvnet_st038_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-04_metpvnet_st024_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-04_metpvnet_st018_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-04_metpvnet_st005_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-02_metpvnet_st086_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-02_metpvnet_st009_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-25_2019-07-02_metpvnet_st007_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-24_2019-07-04_metpvnet_st037_l1a.c01.nc',\n",
       " 'scccJher/2019_metpvnet/l1a/pyrnet_2019-06-24_2019-07-04_metpvnet_st025_l1a.c01.nc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|dropout\n",
    "date = dt.date(2019,8,7)\n",
    "campaign='metpvnet'\n",
    "lvl='l1a'\n",
    "\n",
    "# construct catalog url\n",
    "url = DATA_URL.format(dt=pd.to_datetime(date),campaign=campaign)\n",
    "url = url.replace(\"dodsC\",\"catalog\")\n",
    "url += f\"{lvl}/catalog.xml\"\n",
    "\n",
    "tfiles = get_elements(url)\n",
    "tfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f940bc",
   "metadata": {
    "collapsed": false,
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdt</th>\n",
       "      <th>enddt</th>\n",
       "      <th>campaign</th>\n",
       "      <th>station</th>\n",
       "      <th>collection</th>\n",
       "      <th>sfx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>metpvnet</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>metpvnet</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>metpvnet</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>metpvnet</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>metpvnet</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>metpvnet</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       startdt      enddt  campaign  station  collection sfx\n",
       "20  2019-06-26 2019-07-05  metpvnet       10           1  nc\n",
       "42  2019-07-05 2019-07-08  metpvnet       10           1  nc\n",
       "48  2019-07-08 2019-07-15  metpvnet       10           1  nc\n",
       "74  2019-07-15 2019-07-23  metpvnet       10           1  nc\n",
       "98  2019-07-23 2019-07-30  metpvnet       10           1  nc\n",
       "125 2019-07-30 2019-08-07  metpvnet       10           1  nc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|dropout\n",
    "fn = pkg_res.resource_filename(\"pyrnet\", \"share/pyrnet_config.json\")\n",
    "pyrcfg = pyrutils.read_json(fn)\n",
    "catalog = parse_thredds_catalog(url,pyrcfg[\"output_l1a\"])\n",
    "catalog.query('station==10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec848b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "#|dropout\n",
    "lvl='l1a'\n",
    "station=[86,87]\n",
    "date = dt.datetime(2019,7,31)\n",
    "campaign = 'metpvnet'\n",
    "collection= None\n",
    "\n",
    "lookup_fnames(date,station=station,lvl=lvl,campaign=campaign,collection=collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39688542",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data processed during HDCP2\n",
    "During HDCP2 the raw Pyrnet data was processed with several IDL scripts manually. It is a legacy dataset, which can be accessed under the *old* directory on the Thredds server, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18deaf3d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def read_hdcp2( dt, fill_gaps=True, campaign='hope_juelich'):\n",
    "    \"\"\"\n",
    "    Read HDCP2-formatted datafiles from the pyranometer network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dt: datetime.date\n",
    "        The date of the data to read\n",
    "    fill_gaps: bool\n",
    "        A flag indicating whether gaps should be filled by interpolation\n",
    "    campaign: str\n",
    "        specify campaign ['eifel','hope_juelich','hope_melpitz','lindenberg','melcol']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataset : xarray.Dataset\n",
    "        The pyranometer network observations\n",
    "    \"\"\"\n",
    "    # load dataset\n",
    "    fname = DATA_URL + \"old/nc/\"+ FNAME_FMT_HDCP2\n",
    "    fname = fname.format(dt=dt,\n",
    "                         campaign=campaign,\n",
    "                         campaign_pfx=campaign_pfx[campaign])\n",
    "    ds = xr.open_dataset(fname, mask_and_scale=False)\n",
    "\n",
    "    # select good stations\n",
    "    igood = (np.sum(ds.rsds.data<-900.0,axis=0)<MAX_MISSING)&(np.sum(ds.rsds_flag==1,axis=0)>MIN_GOOD)\n",
    "    ds = ds.isel(nstations=igood)\n",
    "\n",
    "    # fill gaps if requested\n",
    "    if fill_gaps==True:\n",
    "        x = (ds.time-ds.time[0])/np.timedelta64(1,'s')\n",
    "        for i in np.arange(ds.dims['nstations']):\n",
    "            y = ds.rsds.data[:,i]\n",
    "            m = y>-990.0\n",
    "            if not np.all(m):\n",
    "                f = interp1d(x[m],y[m],'linear',bounds_error=False,fill_value='extrapolate')\n",
    "                ds.rsds[~m,i]=f(x[~m])\n",
    "    # add additional DataArrays\n",
    "    jd = (ds.time.data-np.datetime64(sp.EPOCH_JD2000_0))/np.timedelta64(1,'D')\n",
    "    ds['esd'] = sp.earth_sun_distance(jd[0]+0.5)\n",
    "    szen = sp.sun_angles(jd[:,None],ds.lat.data[None,:],ds.lon.data[None,:])[0]\n",
    "    ds['szen']    = xr.DataArray(szen,dims=('time','nstations'),coords={'time':ds.time.data})\n",
    "    ds['mu0']     = np.cos(np.deg2rad(ds.szen))\n",
    "    ds['gtrans']  = ds.rsds/ds.esd**2/SOLCONST/ds['mu0']\n",
    "    return ds.rename({'rsds_flag':'qaflag','rsds':'ghi'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c959344",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data processed by the pyrnet package\n",
    "Data (re-)processed by the pyrnet package is available at the TROPOS thredds server. The following function grant easy access.\n",
    "\n",
    "1. Filename lookup on thredds server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716da34a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "#|dropcode\n",
    "\n",
    "def read_thredds(dates, *, stations, campaign, lvl='l1b', collection=None):\n",
    "    \"\"\"\n",
    "    Read PyrNet data (processed with pyrnet package) from the TROPOS thredds server. Returns one xarray Dataset merged to match the dates and stations input.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dates: list, ndarray, or scalar of type float, datetime or datetime64\n",
    "        A representation of time. If float, interpreted as Julian date.\n",
    "    stations: list, ndarray, or scalar of type int\n",
    "        PyrNet station numbers.\n",
    "    campaign: str\n",
    "        Campaign identifier.\n",
    "    lvl: str\n",
    "        Data processing level -> 'l1a', 'l1b'. The default is 'l1b'.\n",
    "    collection: int or None\n",
    "        Collection number. If None, the latest available collection is looked up. The default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.Dataset\n",
    "        Merged Dataset including all dates and stations specified by the input.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(dates,Iterable):\n",
    "        dates = [dates]\n",
    "\n",
    "    fnames = []\n",
    "    for date in dates:\n",
    "        fnames.extend(\n",
    "            lookup_fnames(\n",
    "                date=date,\n",
    "                station=stations,\n",
    "                lvl=lvl,\n",
    "                campaign=campaign,\n",
    "                collection=collection\n",
    "            )\n",
    "        )\n",
    "    fnames = np.unique(fnames)\n",
    "\n",
    "    url = DATA_URL.format(dt=pd.to_datetime(dates[0]), campaign=campaign)\n",
    "    url += f\"{lvl}/\"\n",
    "    urls = [url+fn for fn in fnames]\n",
    "\n",
    "    ds = xr.open_dataset(urls[0])\n",
    "    for url in urls[1:]:\n",
    "        ds = xr.merge((ds,xr.open_dataset(url)))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68b94e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lvl='l1b'\n",
    "stations=[86, 87]\n",
    "dates = [dt.datetime(2019,8,1), dt.datetime(2019,8,2)]\n",
    "campaign = 'metpvnet'\n",
    "collection= None\n",
    "\n",
    "if not isinstance(dates,Iterable):\n",
    "    dates = [dates]\n",
    "fnames = []\n",
    "for date in dates:\n",
    "    fnames.extend(\n",
    "        lookup_fnames(\n",
    "            date=date,\n",
    "            station=stations,\n",
    "            lvl=lvl,\n",
    "            campaign=campaign,\n",
    "            collection=collection\n",
    "        )\n",
    "    )\n",
    "fnames = np.unique(fnames)\n",
    "url = DATA_URL.format(dt=pd.to_datetime(dates[0]), campaign=campaign)\n",
    "url += f\"{lvl}/\"\n",
    "urls = [url+fn for fn in fnames]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5dc442",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "#|dropout\n",
    "ds = xr.open_dataset(urls[0])\n",
    "for url in urls[1:]:\n",
    "    ds = xr.merge((ds,xr.open_dataset(url)))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec21bc",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "# read pyrnet data and add coordinates\n",
    "def read_pyrnet(date, campaign):\n",
    "    \"\"\" Read pyrnet data and add coordinates\n",
    "    \"\"\"\n",
    "    pyr = read_hdcp2(date, campaign=campaign)\n",
    "    x,y = pyrutils.get_xy_coords(pyr.lon,pyr.lat)\n",
    "    pyr['x'] = xr.DataArray(x,dims=('nstations'))\n",
    "    pyr['y'] = xr.DataArray(y,dims=('nstations'))\n",
    "    return pyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a2948",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "#|dropout\n",
    "date = dt.datetime(2013,7,15)\n",
    "pyr  = read_pyrnet(date, 'hope_juelich')\n",
    "pyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f0bc1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# plot pyranometer locations\n",
    "tstart = int(10.5*3600)\n",
    "tstop  = tstart+2*3600\n",
    "tslice = slice(tstart,tstop)\n",
    "\n",
    "plt.figure()\n",
    "p = plt.plot(pyr.x.data,pyr.y.data,'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745befb",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tstart = int(13.0*3600)\n",
    "tstop  = tstart+2*3600\n",
    "tslice = slice(tstart,tstop)\n",
    "\n",
    "tlim = [\n",
    "    mdates.date2num(pyr.time.data[tslice][0]),\n",
    "    mdates.date2num(pyr.time.data[tslice][-1])\n",
    "]\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "\n",
    "i_sy = np.argsort(-pyr.y.data)\n",
    "im1 = ax.imshow(pyr.gtrans[tslice,i_sy].T, extent=[tlim[0],tlim[1], 1, 1+len(i_sy)], aspect=\"auto\", cmap=\"gray_r\", vmin=0.0, vmax=0.8)\n",
    "_ = ax.set_ylabel(\"# Station\")\n",
    "\n",
    "\n",
    "date_fmt = mdates.DateFormatter('%H:%M')\n",
    "xticks = ax.get_xticks()\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(date_fmt)\n",
    "_ = ax.set_xlabel(\"Time [UTC]\")\n",
    "fig.colorbar(im1, ax=ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ffc71",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Read Calibration Files\n",
    "Calibration factors are collected in share/pyrnet_calibration.json. The following function looks up the nearest calibration in time and fill missing values with earlier calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31e330",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# pyrnet_calibration.json structure\n",
    "calib = {\n",
    "    \"2017-04\":{\n",
    "        \"001\":[7.1,7.2],\n",
    "        \"002\":[7.51,7.61],\n",
    "        \"003\":[6.9,6.91]\n",
    "    },\n",
    "    \"2019-04\": {\n",
    "        \"001\":[7,None],\n",
    "        \"002\":[7.5,7.6]\n",
    "    }\n",
    "}\n",
    "\n",
    "date1 = np.datetime64(\"2019-03-01\") # closer to \"2019-04\" calibration\n",
    "date2 = np.datetime64(\"2018-01-01\") # closer to \"2017-04\" calibration\n",
    "\n",
    "# parse calibration dates\n",
    "cdates = pd.to_datetime(list(calib.keys())).values\n",
    "\n",
    "# sort calib keys beginning with nearest\n",
    "skeys1 = np.array(list(calib.keys()))[np.argsort(np.abs(date1 - cdates))]\n",
    "skeys2 = np.array(list(calib.keys()))[np.argsort(np.abs(date2 - cdates))]\n",
    "print(\"Order of calibration lookup\")\n",
    "print(date1, '->' ,skeys1)\n",
    "print(date2, '->' ,skeys2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5456e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lookup calibration, update with the most recent calibration but fill with earlier calibration if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2e2dd",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# example for date1\n",
    "for i, key in enumerate(skeys1[::-1]):\n",
    "    if i==0:\n",
    "        c = calib[key].copy()\n",
    "        continue\n",
    "\n",
    "    isNone = lambda x: np.any([xi is None for xi in x])\n",
    "    isNotNone = lambda x: np.all([xi is not None for xi in x])\n",
    "    # update with newer calibrations which not include None values\n",
    "    c.update(valfilter(isNotNone, calib[key]))\n",
    "\n",
    "    # update only not None values\n",
    "    for k,v in valfilter(isNone, calib[key]).items():\n",
    "        newv = [c[k][i] if vi is None else vi for i,vi in enumerate(v)]\n",
    "        c.update({k:newv})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf48c2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# example for date2\n",
    "for i, key in enumerate(skeys2[::-1]):\n",
    "    if i==0:\n",
    "        c = calib[key].copy()\n",
    "        continue\n",
    "\n",
    "    isNone = lambda x: np.any([xi is None for xi in x])\n",
    "    isNotNone = lambda x: np.all([xi is not None for xi in x])\n",
    "    # update with newer calibrations which not include None values\n",
    "    c.update(valfilter(isNotNone, calib[key]))\n",
    "\n",
    "    # update only not None values\n",
    "    for k,v in valfilter(isNone, calib[key]).items():\n",
    "        newv = [c[k][i] if vi is None else vi for i,vi in enumerate(v)]\n",
    "        c.update({k:newv})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ccae8",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059f6ca",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def read_calibration(cfile:str, cdate):\n",
    "    \"\"\"\n",
    "    Parse calibration json file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfile: str\n",
    "        Path of the calibration.json\n",
    "    cdate: list, ndarray, or scalar of type float, datetime or datetime64\n",
    "        A representation of time. If float, interpreted as Julian date.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Calibration dictionary sorted by box number.\n",
    "    \"\"\"\n",
    "    cdate = pyrutils.to_datetime64(cdate)\n",
    "    calib = pyrutils.read_json(cfile)\n",
    "    # parse calibration dates\n",
    "    cdates = pd.to_datetime(list(calib.keys())).values\n",
    "    # sort calib keys beginning with nearest\n",
    "    skeys = np.array(list(calib.keys()))[np.argsort(np.abs(cdate - cdates))]\n",
    "    # lookup calibration factors\n",
    "    for i, key in enumerate(skeys[::-1]):\n",
    "        if i==0:\n",
    "            c = calib[key].copy()\n",
    "            continue\n",
    "        isNone = lambda x: np.any([xi is None for xi in x])\n",
    "        isNotNone = lambda x: np.all([xi is not None for xi in x])\n",
    "        # update with newer calibrations which not include None values\n",
    "        c.update(valfilter(isNotNone, calib[key]))\n",
    "        # update only not None values\n",
    "        for k,v in valfilter(isNone, calib[key]).items():\n",
    "            newv = [c[k][i] if vi is None else vi for i,vi in enumerate(v)]\n",
    "            c.update({k:newv})\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8b6f4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Example using the package default pyrnet_calibration.json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32870e26",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "#|dropout\n",
    "fn = pkg_res.resource_filename(\"pyrnet\", \"share/pyrnet_calibration.json\")\n",
    "read_calibration(fn,cdate=np.datetime64(\"2018-09-10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ea879",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Read Box Serial numbers\n",
    "Similar to reading the calibration, pyranometers attached to each box are stored in .json format. Reassigning of pyranometers to certain boxes might happen. Different to the calibration we will look up the most recent entry (not in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8963c",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# pyrnet_calibration.json structure\n",
    "pyrnetmap = {\n",
    "    \"2019-04\": {\n",
    "        \"001\":[\"S11\",None],\n",
    "        \"002\":[\"S21\",\"S33\"]\n",
    "    },\n",
    "    \"2017-04\":{\n",
    "        \"001\":[\"S11\",\"S21\"],\n",
    "        \"002\":[\"S21\",\"S22\"],\n",
    "        \"003\":[\"S31\",None]\n",
    "    },\n",
    "}\n",
    "\n",
    "date1 = np.datetime64(\"2019-03-01\") # before \"2019-04\"\n",
    "date2 = np.datetime64(\"2019-05-01\") # after \"2019-04\"\n",
    "\n",
    "# parse key dates\n",
    "# require sort for lookup later\n",
    "cdates = pd.to_datetime(list(pyrnetmap.keys())).values\n",
    "isort = np.argsort(cdates)\n",
    "\n",
    "# lookup most recent key\n",
    "skeys1 = np.array(list(pyrnetmap.keys()))[isort][np.sum(date1>cdates)-1]\n",
    "skeys2 = np.array(list(pyrnetmap.keys()))[isort][np.sum(date2>cdates)-1]\n",
    "print(\"Order of calibration lookup\")\n",
    "print(date1, '->' ,skeys1)\n",
    "print(date2, '->' ,skeys2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cba665",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we only have to look it up, no merging needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894b6b1",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_pyrnet_mapping(fn:str, date):\n",
    "    \"\"\"\n",
    "    Parse box - serial number mapping  json file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fn: str\n",
    "        Path of the mapping.json\n",
    "    date: list, ndarray, or scalar of type float, datetime or datetime64\n",
    "        A representation of time. If float, interpreted as Julian date.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Calibration dictionary sorted by box number.\n",
    "    \"\"\"\n",
    "    date = pyrutils.to_datetime64(date)\n",
    "    pyrnetmap = pyrutils.read_json(fn)\n",
    "    # parse key dates\n",
    "    # require sort for lookup later\n",
    "    cdates = pd.to_datetime(list(pyrnetmap.keys())).values\n",
    "    isort = np.argsort(cdates)\n",
    "\n",
    "    # lookup most recent key\n",
    "    skey = np.array(list(pyrnetmap.keys()))[isort][np.sum(date>cdates)-1]\n",
    "\n",
    "    return pyrnetmap[skey]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893216d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Lookup Serial, Boxnumber, calibration at certain date\n",
    "Utility to lookup  box metadata for a certain date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b817e2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def meta_lookup(date,*,serial=None,box=None,cfile=None, mapfile=None):\n",
    "    if cfile is None:\n",
    "        cfile = pkg_res.resource_filename(\"pyrnet\", \"share/pyrnet_calibration.json\")\n",
    "    if mapfile is None:\n",
    "        mapfile = pkg_res.resource_filename(\"pyrnet\", \"share/pyrnet_station_map.json\")\n",
    "\n",
    "    map = get_pyrnet_mapping(mapfile,date)\n",
    "    calib = read_calibration(cfile,date)\n",
    "\n",
    "    if serial is None and box is not None:\n",
    "        box=int(box)\n",
    "        return f\"{box:03d}\", map[f\"{box:03d}\"], calib[f\"{box:03d}\"]\n",
    "    elif serial is not None and box is None:\n",
    "        res = valfilter(lambda x: serial in x, map)\n",
    "        box = list(res.keys())[0]\n",
    "        serial = res[box]\n",
    "        return box,serial,calib[box]\n",
    "    else:\n",
    "        raise ValueError(\"At least one of [station,box] have to be specified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7e7e7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "date = np.datetime64(\"2018-10-01\")\n",
    "print(meta_lookup(date,serial=\"S12078.061\"))\n",
    "print(meta_lookup(date,box=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586ea17",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "tags": [
     "remove-cell",
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev.export\n",
    "import nbformat as nbf\n",
    "name = \"pyrnet\"\n",
    "\n",
    "# Export python module\n",
    "nbdev.export.nb_export( f\"{name}.ipynb\" ,f\"../../src/pyrnet\")\n",
    "\n",
    "# Export to docs\n",
    "ntbk = nbf.read(f\"{name}.ipynb\", nbf.NO_CONVERT)\n",
    "\n",
    "text_search_dict = {\n",
    "    \"#|hide\": \"remove-cell\",  # Remove the whole cell\n",
    "    \"#|dropcode\": \"hide-input\",  # Hide the input w/ a button to show\n",
    "    \"#|dropout\": \"hide-output\"  # Hide the output w/ a button to show\n",
    "}\n",
    "for cell in ntbk.cells:\n",
    "    cell_tags = cell.get('metadata', {}).get('tags', [])\n",
    "    for key, val in text_search_dict.items():\n",
    "            if key in cell['source']:\n",
    "                if val not in cell_tags:\n",
    "                    cell_tags.append(val)\n",
    "    if len(cell_tags) > 0:\n",
    "        cell['metadata']['tags'] = cell_tags\n",
    "    nbf.write(ntbk, f\"../../docs/source/nbs/{name}.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrnet",
   "language": "python",
   "name": "pyrnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
